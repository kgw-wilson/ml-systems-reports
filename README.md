# Machine Learning Systems Reports

Code available upon request.

This repository contains two applied machine learning reports focused on real-world ML systems, evaluation, and limitations. The projects were completed as part of coursework, independent exploration, and competitive events during my first semester at UW-Madison. The technical reports document experimental results and analysis.

## Project 1: Prompt Engineering for Diversity in Text-to-Image Models

#### Overview

This project investigates whether prompt engineering alone can measurably reduce demographic bias in images generated by large text-to-image models (specifically DALL·E 2). The core contribution is a quantitative evaluation framework for assessing bias across generated images, rather than relying purely on qualitative inspection.

A small standardized dataset of prompts was created as a proof of concept. Images generated from these prompts were evaluated using both automated facial analysis tools and manual annotation. A proposed diversity score, based on weighted chi-squared distances between observed and target demographic distributions (age, sex, race), was used to compare baseline prompts against diversified prompts.

#### Key Results

•	Prompt engineering significantly reduced measured demographic bias in generated images

•	Manual annotation showed a 4× improvement in the diversity score when using diversified prompts

•	Automated facial analysis tools (e.g., DeepFace) were found to be unreliable, particularly for non-white faces

Full methodology, results, and discussion are provided in the accompanying report.

#### Limitations

•	Small prompt dataset (30 prompts) limits generalizability

•	Diversity score formulation and weighting are heuristic and require further validation

•	Automated facial classifiers performed poorly on generated images

•	Manual labeling does not scale

#### Ethical Considerations

•	The project explicitly addresses bias in generative models, not the creation or deployment of such models

•	Automated demographic classification tools themselves embed biases and must be treated cautiously

•	Results should not be interpreted as proof that prompt engineering “solves” bias, but rather as evidence that surface-level mitigations can measurably affect outputs

## Project 2: Distributed Facial Recognition Attendance System

#### Backstory

This project began as a hackathon prototype built during UW–Madison’s largest annual hackathon, CheesHacks. I entered the competition with a team of three other students, where we designed and implemented a working facial-recognition-based attendance system with a polished UI. The project won first place and the $500 grand prize.

That system featured a React frontend and Flask backend, and the academic version of the project expanded on this prototype with deeper technical evaluation and analysis.

#### Overview

The system explores the feasibility of a distributed facial recognition pipeline for attendance tracking. Images captured on an instructor’s device are sent to a server, where the following steps occur:

1.	Face detection using MTCNN
  
2.	Liveness detection using a ResNet-18–based model
  
3.	Face embedding generation using Inception ResNet V1
  
4.	Identity matching using cosine similarity

The project emphasizes end-to-end system behavior, latency, scalability, and robustness rather than maximizing accuracy on a curated dataset.

#### Key Results

•	End-to-end inference latency was dominated by liveness detection

•	Linear embedding search scaled poorly for large class sizes

•	Recognition accuracy degraded significantly under changes in lighting, pose, and appearance

•	Liveness detection struggled with modern high-resolution phone displays

#### Limitations

•	My implementation of embedding search was not scalable for large populations and should be replaced with more efficient search operations

•	One-shot enrollment makes the system sensitive to appearance changes

•	Liveness detection models were slow and brittle

•	Performance dropped sharply for non-frontal poses

#### Ethical Considerations

•	Facial recognition systems raise serious concerns around privacy, consent, and misuse

•	Bias in face recognition and liveness detection models can disproportionately affect certain groups

•	This project is presented as a technical exploration, not an endorsement of facial recognition for attendance or surveillance

•	Any real-world deployment would require explicit consent, strong safeguards, and institutional oversight
